# anomaly_detection_persistent_homology
Detecting anomalous texts with persistent homology of context vectors computed by individual attention heads in language transformers

## Some Heuristics and Guiding Principles

We must note that this form of anomalous text detection is not perfect, and as seen in the notebooks, there are false positive and false negatives. There are some things we should keep in mind while using this methods of anomaly detection. The length of the text matters. If one of the texts is significantly larger that the others in terms of token count, then it has a higher chance of being labeled an anomaly, regardless of whether it is on the same topic as the baseline texts. The next thing to keep in mind is that if the baseline texts too loosely clustered around the Fréchet mean, this makes detecting outliers (anomalous text) more difficult. This can happen if the topics mentioned in the baseline texts are only loosely related in content. For example, if we have baseline text talking more extensively about the applications of deep learning to healthcare, with an emphasis on healthcare applications, this will likely be considered an outlier in the initial calculation of the Féchet mean. This also leaves us open to the possibility of *not detecting* a text about healthcare instead of deep learning as anomalous. We must also note that some models perform better at this than others. For example, `xlm-roberta-large` forms better persistent homology features than `xlm-roberta-base` on average. We must also take note of the fact that certain heads may perform better than others for certain topic classes as well. This is an interesting feature of this analysis that is as much about anomaly detection as it is about analyzing the topics modeled by individual heads of the model. 
